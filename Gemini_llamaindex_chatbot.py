# -*- coding: utf-8 -*-
"""Task:  Build a Simple Chatbot with LlamaIndex(Module 5 Part 1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gwv6LzuFk9t8V63z0VpiV1ozmBRDbmxC

# Library Installation
"""

!pip install llama-index-llms-gemini llama-index

"""# Set Up Gemini API Key"""

# Set API key (replace with your actual API key)
import os
GEMINI_API_KEY = "AIzaSyB7f1G7oeXiL1OV6f2N2yxdE0rSkYPFlKA"  # Replace with your actual API key
os.environ["GEMINI_API_KEY"] = GEMINI_API_KEY

"""# Build simple chatbox"""

# Import necessary modules
from llama_index.llms.gemini import Gemini
from llama_index.core.llms import ChatMessage

# The client gets the API key from the environment variable `GEMINI_API_KEY`.
client = genai.Client()

#  Initialize the Gemini model
llm = Gemini(
    model="gemini-2.5-flash",

)

def simple_chatbot():
    """
    A simple interactive chatbot using Gemini with LlamaIndex.
    """
    print(" Simple Gemini Chatbot ")
    print("Type 'exit' to end the conversation")
    print("-" * 50)

    # Initialize chat history
    messages = []

    while True:
        # Get user input
        user_input = input("\nYou: ")

        # Check for exit command
        if user_input.lower() in ["exit", "quit", "bye"]:
            print("\nChatbot: Goodbye! Have a great day!")
            break

        # Add user message to history
        messages.append(ChatMessage(role="user", content=user_input))

        try:
            # Get response from Gemini
            response = llm.chat(messages)

            # Print the response
            print(f"\nChatbot: {response.message.content}")

            # Add assistant response to history
            messages.append(ChatMessage(role="assistant", content=response.message.content))

        except Exception as e:
            print(f"\nError: {e}")
            print("Please try again or check your API key")

# Run the chatbot
if __name__ == "__main__":
    simple_chatbot()